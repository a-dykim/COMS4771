{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm \n",
    "from scipy.stats import bernoulli\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "\n",
    "kDim = 5 # the number of dimension\n",
    "# kUsers = 610 # 610 is total, but we use 300 users \n",
    "# kMovies = 9724 # 9724 is total, but we use 6000 movies\n",
    "\n",
    "# These data are used to draw a kDim-vector that follows Gaussian Distribution (kMean, kCov)\n",
    "kMean = []\n",
    "for i in range(kDim):\n",
    "    kMean.append(0)\n",
    "kCov = 0.1 * np.identity(n=kDim,dtype='float')\n",
    "\n",
    "# Rating matrix, which is sparsew\n",
    "gR = dict() # Key = (userId, movieId)\n",
    "gD = dict() # Key = (userId, moveId) value = existence\n",
    "gU = dict() # Key = (userId), value = user vector\n",
    "gV = dict() # Key = (movieId), value = movie vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all model variables reading given file(csv)\n",
    "# It should be executed first before calling MakeTestSet which split the whole file into \n",
    "# training file and test file\n",
    "def GenerateModelVariables (in_file_name, in_U, in_V):\n",
    "    file = open(in_file_name, 'r')\n",
    "    fileReader = csv.reader(file)\n",
    "    \n",
    "    for row in fileReader:\n",
    "        if row[0] == 'userId':\n",
    "            continue\n",
    "        else:\n",
    "            currentUserID = int(row[0])\n",
    "            currentMovieID = int(row[1])\n",
    "            currentRating = float(row[2])\n",
    "\n",
    "            if type(in_U.get(currentUserID)) == type(None):\n",
    "                in_U[currentUserID] = np.random.multivariate_normal(kMean, kCov, 1).T\n",
    "            if type(gV.get(currentMovieID)) == type(None):\n",
    "                in_V[currentMovieID] = np.random.multivariate_normal(kMean, kCov, 1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test set... from given training file\n",
    "def MakeTestSet(in_file_name, in_ratio, out_trainingFileName, out_testFileName):\n",
    "    originalFile = open(in_file_name, 'r')\n",
    "    fileReader = csv.reader(originalFile)\n",
    "    \n",
    "    trainingFile = open(out_trainingFileName,'w')\n",
    "    testFile = open(out_testFileName, 'w')\n",
    "    \n",
    "    trainingCSVWriter = csv.writer(trainingFile, delimiter=',',quotechar=',', quoting=csv.QUOTE_MINIMAL)\n",
    "    testCSVWriter = csv.writer(testFile, delimiter=',',quotechar=',', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    trainingCSVWriter.writerow(['userId', 'movieId', 'rating'])\n",
    "    testCSVWriter.writerow(['userId', 'movieId', 'rating'])\n",
    "    \n",
    "    for row in fileReader:\n",
    "        if row[0] == 'userId':\n",
    "            continue\n",
    "        else:\n",
    "            bTrainingSet = bernoulli.rvs(in_ratio, size = 1)[0] # 1 indicates training data\n",
    "            if bTrainingSet == 1:\n",
    "                trainingCSVWriter.writerow([row[0], row[1], row[2]])\n",
    "            else:\n",
    "                testCSVWriter.writerow([row[0], row[1], row[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training file\n",
    "# This function extract all information on the set of given ratings and existence\n",
    "def ReadTrainingCSVFile(in_file_name, out_D, out_R):\n",
    "    training_file = open(in_file_name, 'r')\n",
    "    fileReader = csv.reader(training_file)\n",
    "    \n",
    "    for row in fileReader:\n",
    "        if row[0] == 'userId':\n",
    "            continue\n",
    "        else:            \n",
    "            currentUserID = int(row[0])\n",
    "            currentMovieID = int(row[1])\n",
    "            currentRating = float(row[2])\n",
    "                        \n",
    "            out_D[(currentUserID, currentMovieID)] = 1\n",
    "            out_R[(currentUserID, currentMovieID)] = currentRating\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is used to verify that the objective function is minimizing\n",
    "def CalculateJointLikelihood(in_R, in_U, in_V, in_D):\n",
    "    \n",
    "    logLikelihood = 0.0\n",
    "    \n",
    "    for eachKey in in_D.keys():\n",
    "        logLikelihood = logLikelihood + ((in_R[eachKey] - (in_U[eachKey[0]].T @ in_V[eachKey[1]])) ** 2)\n",
    "    \n",
    "    return logLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We solve this problem iteratively. \n",
    "# For example, first set all U, V = 0\n",
    "#\n",
    "# For the first iteration:\n",
    "# Calculate U using given V\n",
    "# Next, \n",
    "# Calculate V using calculated U above.\n",
    "\n",
    "def CalculateMLE(in_init_U, in_init_V, in_D, in_R, in_nIterations):\n",
    "    \n",
    "    U = copy.deepcopy(in_init_U) # init U\n",
    "    V = copy.deepcopy(in_init_V) # init V\n",
    "    \n",
    "    for t in range(in_nIterations):\n",
    "        for i in U.keys():\n",
    "            firstTerm = np.zeros([kDim, kDim], float)\n",
    "            secondTerm = np.zeros([kDim, 1], float)\n",
    "\n",
    "            for j in V.keys():\n",
    "                if type(in_D.get((i,j))) != type(None):\n",
    "                    \n",
    "                    firstTerm = firstTerm + (V[j] @ V[j].T)\n",
    "                    secondTerm = secondTerm + (in_R[(i, j)] * V[j])\n",
    "            \n",
    "            U[i] = np.linalg.pinv(firstTerm) @ secondTerm\n",
    "\n",
    "        for j in V.keys():\n",
    "            firstTerm = np.zeros([kDim, kDim], float)\n",
    "            secondTerm = np.zeros([kDim, 1], float)\n",
    "\n",
    "            for i in U.keys():\n",
    "                if type(in_D.get((i,j))) != type(None):\n",
    "                    \n",
    "                    firstTerm = firstTerm + (U[i] @ U[i].T)\n",
    "                    secondTerm = secondTerm + (in_R[(i, j)] * U[i])\n",
    "            \n",
    "            V[j] = np.linalg.pinv(firstTerm) @ secondTerm\n",
    "        \n",
    "        # calculate current joint likelihood\n",
    "        currentLikelihood = CalculateJointLikelihood(in_D=gD, in_R= gR, in_U=U, in_V=V)\n",
    "        \n",
    "        # Show the current value of objective function\n",
    "        print(\"Value => \", currentLikelihood)\n",
    "        \n",
    "    return U, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSample_UV(in_init_U, in_init_V, in_R, in_D, in_nSamples, in_stepSize):\n",
    "    \n",
    "    U = copy.deepcopy(in_init_U) # init U\n",
    "    V = copy.deepcopy(in_init_V) # init V\n",
    "    \n",
    "    nUsers = len(U)\n",
    "    nMovies = len(V)\n",
    "    c = 1.0\n",
    "    \n",
    "    u_samples = []\n",
    "    v_samples = []\n",
    "    \n",
    "    for n in range(in_nSamples):\n",
    "        for t in range(in_stepSize):\n",
    "            print(\"iteration => \", t)\n",
    "            for i in U.keys():\n",
    "                firstTerm = np.identity(n=kDim,dtype='float') / c\n",
    "                secondTerm = np.zeros([kDim,1],dtype='float')\n",
    "\n",
    "                for j in V.keys():\n",
    "                    if type(in_D.get((i,j))) != type(None):\n",
    "                        firstTerm = firstTerm + (V[j] @ V[j].T)\n",
    "                        secondTerm = secondTerm + (in_R[(i, j)] * V[j])\n",
    "\n",
    "                covTerm = np.linalg.inv(firstTerm)\n",
    "                muTerm = (covTerm @ secondTerm).T\n",
    "\n",
    "                U[i] = np.random.multivariate_normal(muTerm[0], covTerm, 1).T\n",
    "\n",
    "            for j in V.keys():\n",
    "                firstTerm = np.identity(n=kDim,dtype='float') / c\n",
    "                secondTerm = np.zeros([kDim,1],dtype='float')\n",
    "\n",
    "                for i in U.keys():\n",
    "                    if type(in_D.get((i,j))) != type(None):\n",
    "\n",
    "                        firstTerm = firstTerm + (U[i] @ U[i].T)\n",
    "                        secondTerm = secondTerm + (in_R[(i, j)] * U[i])\n",
    "\n",
    "                covTerm = np.linalg.inv(firstTerm)\n",
    "                muTerm = (covTerm @ secondTerm).T\n",
    "\n",
    "                V[j] = np.random.multivariate_normal(muTerm[0], covTerm, 1).T\n",
    "        \n",
    "        print(\"We've got one sample from full posterior distribution\")\n",
    "        u_samples.append(U)\n",
    "        v_samples.append(V)\n",
    "    return u_samples,v_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllErrors_GibbsVersion(in_testFileName, in_D, in_R, in_init_U, in_init_V, in_nSamples):\n",
    "    \n",
    "    USamples, VSamples = GetSample_UV(in_D=in_D,\n",
    "                                      in_R=in_R,\n",
    "                                      in_init_U=in_init_U,\n",
    "                                      in_init_V=in_init_V,\n",
    "                                      in_nSamples=in_nSamples,\n",
    "                                      in_stepSize=10)\n",
    "    \n",
    "    trainingSquaredErrorSum = 0.0\n",
    "    testSquaredErrorSum = 0.0\n",
    "    \n",
    "    ##### training error\n",
    "    for eachKey in in_D.keys():\n",
    "        sum = 0.0\n",
    "        for n in range(in_nSamples):\n",
    "            sum = sum + (USamples[n][eachKey[0]].T @ VSamples[n][eachKey[1]])[0][0]\n",
    "        sum = sum / float(in_nSamples)\n",
    "        trainingSquaredErrorSum = trainingSquaredErrorSum + ((in_R[eachKey] - sum) ** 2)\n",
    "    \n",
    "    trainingSquaredErrorSum = trainingSquaredErrorSum / len(gR)\n",
    "    print('Training Error (Gibbs)', trainingSquaredErrorSum)\n",
    "    \n",
    "    #### test error\n",
    "    test_file = open(in_testFileName, 'r')\n",
    "    fileReader = csv.reader(test_file)\n",
    "    \n",
    "    testSquaredErrorSum = 0.0\n",
    "    testSetCount = 0\n",
    "    for row in fileReader:\n",
    "        if row[0] == 'userId':\n",
    "            continue\n",
    "        else:\n",
    "            testSetCount = testSetCount + 1\n",
    "            currentUserID = int(row[0])\n",
    "            currentMovieID = int(row[1])\n",
    "            currentRating = float(row[2])\n",
    "                \n",
    "            sum = 0.0\n",
    "            for n in range(in_nSamples):\n",
    "                sum = sum + (USamples[n][currentUserID].T @ VSamples[n][currentMovieID])[0][0]\n",
    "            estimatedRating = sum / float(in_nSamples)\n",
    "            \n",
    "            testSquaredErrorSum = testSquaredErrorSum + ((estimatedRating - currentRating) ** 2)\n",
    "    \n",
    "    testSquaredErrorSum = testSquaredErrorSum / float(testSetCount)\n",
    "    print('Test Error (Gibbs)', testSquaredErrorSum)\n",
    "    \n",
    "    return trainingSquaredErrorSum, testSquaredErrorSum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllErrors_MLEVersion(in_testFileName, in_D, in_R, in_init_U, in_init_V, in_nIterations):\n",
    "    \n",
    "    U, V = CalculateMLE(gU, gV, gD, gR, in_nIterations)\n",
    "    trainingSquaredErrorSum = 0.0\n",
    "    testSquaredErrorSum = 0.0\n",
    "    \n",
    "    ##### training error\n",
    "    for eachKey in in_D.keys():\n",
    "        trainingSquaredErrorSum = trainingSquaredErrorSum + (((U[eachKey[0]].T @ V[eachKey[1]])[0][0] - in_R[eachKey]) ** 2)\n",
    "    \n",
    "    trainingSquaredErrorSum = trainingSquaredErrorSum / len(gR)\n",
    "    print('Training Error (MLE)', trainingSquaredErrorSum)\n",
    "    \n",
    "    #### test error\n",
    "    test_file = open(in_testFileName, 'r')\n",
    "    fileReader = csv.reader(test_file)\n",
    "    \n",
    "    testSquaredErrorSum = 0.0\n",
    "    testSetCount = 0\n",
    "    testErrorList = []\n",
    "    for row in fileReader:\n",
    "        if row[0] == 'userId':\n",
    "            continue\n",
    "        else:\n",
    "            testSetCount = testSetCount + 1\n",
    "            currentUserID = int(row[0])\n",
    "            currentMovieID = int(row[1])\n",
    "            currentRating = float(row[2])\n",
    "                \n",
    "            estimatedRating = (U[currentUserID].T @ V[currentMovieID])[0][0]\n",
    "            testSquaredErrorSum = testSquaredErrorSum + ((estimatedRating - currentRating) ** 2)\n",
    "            testErrorList.append(((estimatedRating - currentRating) ** 2))\n",
    "    \n",
    "    testSquaredErrorSum = testSquaredErrorSum / float(testSetCount)\n",
    "    print('Test Error (MLE)', testSquaredErrorSum)\n",
    "    \n",
    "    return trainingSquaredErrorSum, testSquaredErrorSum, testErrorList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear\n",
    "gU.clear()\n",
    "gV.clear()\n",
    "gD.clear()\n",
    "gR.clear()\n",
    "\n",
    "# Get all user id and movie id in order to avoid encontering unseen user or movie \n",
    "GenerateModelVariables (in_file_name='movie_ratings.csv', in_U=gU, in_V=gV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "Training Error (Gibbs) 0.6530830892765931\n",
      "Test Error (Gibbs) 1.9016753784821465\n",
      "Value =>  [[392002.68651324]]\n",
      "Value =>  [[201244.77504182]]\n",
      "Value =>  [[130008.89244096]]\n",
      "Value =>  [[93780.28441072]]\n",
      "Value =>  [[73212.40812779]]\n",
      "Value =>  [[60853.44621468]]\n",
      "Value =>  [[53891.39153748]]\n",
      "Value =>  [[49354.81301]]\n",
      "Value =>  [[46206.69441016]]\n",
      "Value =>  [[43912.44040278]]\n",
      "Value =>  [[42102.66853649]]\n",
      "Value =>  [[40586.37479017]]\n",
      "Value =>  [[39362.35641412]]\n",
      "Value =>  [[38429.80989143]]\n",
      "Value =>  [[37750.84452558]]\n",
      "Value =>  [[37256.53372469]]\n",
      "Value =>  [[36880.01678102]]\n",
      "Value =>  [[36578.53767273]]\n",
      "Value =>  [[36320.14315305]]\n",
      "Value =>  [[36094.16580091]]\n",
      "Value =>  [[35893.57773902]]\n",
      "Value =>  [[35712.7264176]]\n",
      "Value =>  [[35542.06233636]]\n",
      "Value =>  [[35375.4511025]]\n",
      "Value =>  [[35211.67305202]]\n",
      "Value =>  [[35050.4455731]]\n",
      "Value =>  [[34887.77340671]]\n",
      "Value =>  [[34720.1608778]]\n",
      "Value =>  [[34546.16802166]]\n",
      "Value =>  [[34363.56597078]]\n",
      "Training Error (MLE) 0.5266931207587017\n",
      "Test Error (MLE) 878404.3651422345\n",
      "One Split Done\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "iteration =>  0\n",
      "iteration =>  1\n",
      "iteration =>  2\n",
      "iteration =>  3\n",
      "iteration =>  4\n",
      "iteration =>  5\n",
      "iteration =>  6\n",
      "iteration =>  7\n",
      "iteration =>  8\n",
      "iteration =>  9\n",
      "We've got one sample from full posterior distribution\n",
      "Training Error (Gibbs) 0.6394996395925756\n",
      "Test Error (Gibbs) 0.9811104168495841\n",
      "Value =>  [[508407.97528637]]\n",
      "Value =>  [[213564.51558517]]\n",
      "Value =>  [[123285.50160588]]\n",
      "Value =>  [[87738.87346662]]\n",
      "Value =>  [[71627.18563729]]\n",
      "Value =>  [[63816.1705114]]\n",
      "Value =>  [[59407.68117143]]\n",
      "Value =>  [[56702.64234421]]\n",
      "Value =>  [[54737.17145154]]\n",
      "Value =>  [[53273.57789639]]\n",
      "Value =>  [[52250.30217967]]\n",
      "Value =>  [[51617.86995688]]\n",
      "Value =>  [[51206.91762495]]\n",
      "Value =>  [[50907.83263869]]\n",
      "Value =>  [[50661.96666049]]\n",
      "Value =>  [[50462.85096617]]\n",
      "Value =>  [[50296.98275739]]\n",
      "Value =>  [[50150.17591898]]\n",
      "Value =>  [[50017.27062164]]\n",
      "Value =>  [[49897.15627078]]\n",
      "Value =>  [[49788.17088206]]\n",
      "Value =>  [[49690.11435188]]\n",
      "Value =>  [[49600.23273515]]\n",
      "Value =>  [[49516.43364333]]\n",
      "Value =>  [[49435.39664898]]\n",
      "Value =>  [[49359.30383421]]\n"
     ]
    }
   ],
   "source": [
    "splitList = [0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.99]\n",
    "splitIndex = ['65%', '70%', '75%', '80%', '85%', '90%', '95%', '99%']\n",
    "\n",
    "MLEMSETestErrorsLists = [] # List of List\n",
    "MLETrainingMSE_List = []\n",
    "MLETestMSE_List = []\n",
    "\n",
    "gibbsTrainingMSE_List = []\n",
    "gibbsTestMSE_List = []\n",
    "\n",
    "\n",
    "for i in range(len(splitList)):\n",
    "    # Split the movie_ratings.csv file into traingSet.csv, testSet.csv\n",
    "    MakeTestSet('movie_ratings.csv', splitList[i], 'trainingSet.csv', 'testSet.csv')\n",
    "    \n",
    "    # Read training data file to read given ratings.\n",
    "    ReadTrainingCSVFile(in_file_name=\"trainingSet.csv\", out_D=gD,out_R=gR)\n",
    "\n",
    "    # For gibbs model\n",
    "    currentGibbsTrainingMSE = 0.0\n",
    "    currentGibbsTestMSE = 0.0\n",
    "    \n",
    "    currentGibbsTrainingMSE, currentGibbsTestMSE = GetAllErrors_GibbsVersion(in_D=gD, in_R=gR,in_init_U=gU,in_init_V=gV,in_nSamples=10,in_testFileName='testSet.csv')\n",
    "    gibbsTrainingMSE_List.append(currentGibbsTrainingMSE)\n",
    "    gibbsTestMSE_List.append(currentGibbsTestMSE)\n",
    "    \n",
    "    # For MLE model\n",
    "    currentMLETrainingMSE = 0.0\n",
    "    currentMLETestMSE = 0.0\n",
    "    currentMLEMSETestErrorLists = []\n",
    "    \n",
    "    currentMLETrainingMSE, currentMLETestMSE, currentMLEMSETestErrorLists = GetAllErrors_MLEVersion(in_D=gD, in_R=gR, in_init_U=gU, in_init_V=gV,in_testFileName='testSet.csv',in_nIterations=30)\n",
    "    MLETrainingMSE_List.append(currentMLETrainingMSE)\n",
    "    MLETestMSE_List.append(currentMLETestMSE)\n",
    "    MLEMSETestErrorsLists.append(currentMLEMSETestErrorLists)\n",
    "    \n",
    "    # Remove 'trainingSet.csv', and 'testSet.csv' files for the next experiment\n",
    "    os.remove(\"trainingSet.csv\")\n",
    "    os.remove(\"testSet.csv\")\n",
    "    print('One Split Done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLEMSETestErrorsLists # List of List\n",
    "print(\"MLE Training\", MLETrainingMSE_List)\n",
    "print(\"MLE Test\", MLETestMSE_List)\n",
    "\n",
    "gibbsTrainingMSE_List\n",
    "print(\"Gibbs Training\",gibbsTrainingMSE_List)\n",
    "print(\"Gibbs Test\",gibbsTestMSE_List)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.plot(MLETestMSE_List ,'o--', color='darkgreen' )\n",
    "plt.plot(MLETrainingMSE_List, 'o--', color='blue')\n",
    "plt.xticks(range(len(splitIndex)), splitIndex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "gibbsTrainingMSE_List = []\n",
    "gibbsTestMSE_List = []\n",
    "\n",
    "plt.plot(gibbsTrainingMSE_List ,'o--', color='darkgreen')\n",
    "plt.plot(gibbsTestMSE_List, 'o--', color='blue')\n",
    "plt.xticks(range(len(splitIndex)), splitIndex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
