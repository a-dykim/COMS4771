{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "import nltk\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ham_address = '/Volumes/Extra/Columbia/Fall2018/Classes/ML/enron1/ham/'\n",
    "spam_address = '/Volumes/Extra/Columbia/Fall2018/Classes/ML/enron1/spam/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_file = open('/Volumes/Extra/Columbia/Fall2018/Classes/ML/enron1/Summary.txt')\n",
    "summary = summary_file.read()\n",
    "summary_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hams = []\n",
    "hamfiles = sorted(glob.glob(ham_address+'*.txt'))\n",
    "hfiles = len(hamfiles)\n",
    "for i in range(hfiles):\n",
    "    file = open(hamfiles[i], 'rt')\n",
    "    text = file.read()\n",
    "    hams.append(text)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spams = []\n",
    "spamfiles = sorted(glob.glob(spam_address+'*.txt'))\n",
    "sfiles = len(spamfiles)\n",
    "for i in range(sfiles):\n",
    "    file = open(spamfiles[i], 'rt', encoding=\"latin-1\")\n",
    "    text = file.read()\n",
    "    spams.append(text)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## word stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "ps = PorterStemmer()\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = ['I likes you like you tree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "words=tokenizer.tokenize(phrase[0])\n",
    "emp = []\n",
    "for w in words:\n",
    "    emp.append(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'like', 'you', 'like', 'you', 'tree']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embed_one(datalist):\n",
    "    \"\"\"\n",
    "    Construct stemmed+bag-of-words model for individual then construct an array of individual bags\n",
    "    \n",
    "    Returns\n",
    "    a collection of individual set dict corresponding to its counts\n",
    "    \"\"\"\n",
    "    bag_collection = []\n",
    "    ndata = len(datalist)\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    for i in range(ndata):\n",
    "        stemmed = []\n",
    "        token = tokenizer.tokenize(datalist[i])\n",
    "        for w in token:\n",
    "            stemmed.append(ps.stem(w))\n",
    "    \n",
    "        stemmed = list(set(stemmed))\n",
    "        nstem = len(stemmed)\n",
    "        one_bag = {}\n",
    "        \n",
    "        for j in range(nstem):\n",
    "            key = stemmed[j]\n",
    "            if key in one_bag:\n",
    "                one_bag[key] += 1\n",
    "            else:\n",
    "                one_bag[key] = 1\n",
    "        bag_collection.append(one_bag)\n",
    "        \n",
    "    return bag_collection\n",
    "\n",
    "def embed_whole(datalist):\n",
    "    \"\"\"\n",
    "    From a list of data (should have multiple), do stemming (+remove non-words) then apply the bag-of-words model\n",
    "    \n",
    "    Returns\n",
    "    a dictionary of bag-of-words each dic corresponding to its counts\n",
    "    \"\"\"\n",
    "    bag = {}\n",
    "    ndata = len(datalist)\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    for i in range(ndata):\n",
    "        stemmed = []\n",
    "        token = tokenizer.tokenize(datalist[i])\n",
    "        for w in token:\n",
    "            stemmed.append(ps.stem(w))\n",
    "    \n",
    "        stemmed = list(set(stemmed))\n",
    "        nstem = len(stemmed)\n",
    "        for j in range(nstem):\n",
    "            key = stemmed[j]\n",
    "            if key in bag:\n",
    "                bag[key] += 1\n",
    "            else:\n",
    "                bag[key] = 1        \n",
    "    return bag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_one_bag = embed_one(hams)\n",
    "spam_one_bag = embed_one(spams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whole = np.concatenate((hams, spams))\n",
    "whole_bag = embed_data(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_sum_bag = embed_whole(spams)\n",
    "ham_sum_bag = embed_whole(hams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cholesterol': 18,\n",
       " 'alert': 36,\n",
       " 'begin': 44,\n",
       " 'resist': 6,\n",
       " 'in': 618,\n",
       " 'potenc': 3,\n",
       " 'least': 17,\n",
       " '90': 66,\n",
       " 'but': 203,\n",
       " 'restor': 8,\n",
       " 'wound': 11,\n",
       " 'heal': 5,\n",
       " '95': 56,\n",
       " 'sexual': 45,\n",
       " 'by': 350,\n",
       " 'are': 495,\n",
       " 'hair': 14,\n",
       " 'skin': 20,\n",
       " 'we': 555,\n",
       " 'densiti': 2,\n",
       " 'our': 452,\n",
       " 'up': 257,\n",
       " 'less': 94,\n",
       " 'refer': 47,\n",
       " 'is': 671,\n",
       " 'gone': 20,\n",
       " 'strength': 8,\n",
       " 'nearli': 16,\n",
       " 'ha': 227,\n",
       " 'as': 396,\n",
       " 'read': 83,\n",
       " 'introduc': 22,\n",
       " 'level': 39,\n",
       " 'hgh': 5,\n",
       " 'subject': 1500,\n",
       " 'reduc': 34,\n",
       " 'improv': 50,\n",
       " 'forti': 7,\n",
       " 'stabil': 6,\n",
       " 'young': 32,\n",
       " 'lower': 30,\n",
       " 'doctor': 89,\n",
       " 'near': 36,\n",
       " 'everyon': 37,\n",
       " 'heart': 25,\n",
       " 'scienc': 12,\n",
       " 'sleep': 37,\n",
       " 'common': 21,\n",
       " 'it': 542,\n",
       " 'swing': 5,\n",
       " 'growth': 54,\n",
       " 'produc': 41,\n",
       " 'human': 12,\n",
       " 'increas': 105,\n",
       " 'mood': 3,\n",
       " 'dobmeo': 1,\n",
       " 'master': 18,\n",
       " 'advantag': 33,\n",
       " 'thi': 563,\n",
       " 'pressur': 8,\n",
       " 'hormon': 5,\n",
       " 'and': 866,\n",
       " 'at': 415,\n",
       " 'with': 534,\n",
       " 'formul': 6,\n",
       " 'diminish': 1,\n",
       " 'cellulit': 3,\n",
       " 'normal': 44,\n",
       " 'wrinkl': 9,\n",
       " 'muscl': 31,\n",
       " 'textur': 1,\n",
       " 'unsubscrib': 68,\n",
       " 'plenti': 11,\n",
       " 'bodi': 66,\n",
       " 'quicken': 1,\n",
       " 'eighti': 4,\n",
       " 'emot': 9,\n",
       " 'fat': 27,\n",
       " 'energi': 54,\n",
       " 'defici': 1,\n",
       " 'disappear': 5,\n",
       " 'also': 171,\n",
       " 'websit': 72,\n",
       " 'loss': 59,\n",
       " 'strengthen': 5,\n",
       " 'when': 121,\n",
       " 'color': 34,\n",
       " 'product': 233,\n",
       " 'more': 422,\n",
       " 'to': 960,\n",
       " 'call': 87,\n",
       " 'vision': 9,\n",
       " 'twenti': 19,\n",
       " 'the': 905,\n",
       " 'thick': 5,\n",
       " 'of': 714,\n",
       " 'one': 280,\n",
       " 'control': 59,\n",
       " 'bone': 9,\n",
       " 'time': 304,\n",
       " 'new': 250,\n",
       " 'stukm': 1,\n",
       " 'blood': 17,\n",
       " 'memori': 17,\n",
       " 'medic': 117,\n",
       " 'mental': 8,\n",
       " 'ill': 11,\n",
       " 'veri': 107,\n",
       " 'my': 138,\n",
       " 'age': 51,\n",
       " 'oxwq': 1,\n",
       " 'take': 191,\n",
       " 'thank': 169,\n",
       " 'prescrib': 9,\n",
       " 'will': 328,\n",
       " 'direct': 42,\n",
       " 'secur': 168,\n",
       " 'approv': 80,\n",
       " 'ultram': 11,\n",
       " 'fast': 56,\n",
       " 'click': 216,\n",
       " 'overnight': 33,\n",
       " 'ogrg': 1,\n",
       " 'z': 40,\n",
       " 'mani': 143,\n",
       " 'prescript': 116,\n",
       " 'low': 106,\n",
       " 'fda': 24,\n",
       " 'your': 756,\n",
       " 'a': 844,\n",
       " 'pharmaci': 55,\n",
       " 'for': 822,\n",
       " 'off': 115,\n",
       " 'physician': 21,\n",
       " 'order': 182,\n",
       " 'vicodin': 29,\n",
       " 'list': 133,\n",
       " 'licens': 46,\n",
       " 'me': 218,\n",
       " 'lqlokeolnq': 1,\n",
       " 'doorstep': 9,\n",
       " 'write': 50,\n",
       " 'adipex': 10,\n",
       " 'us': 286,\n",
       " 'via': 92,\n",
       " 'you': 868,\n",
       " 'soma': 34,\n",
       " 'door': 46,\n",
       " 'ship': 139,\n",
       " 'lnu': 1,\n",
       " 'cost': 102,\n",
       " 'here': 453,\n",
       " 'no': 482,\n",
       " 'an': 295,\n",
       " 'readi': 36,\n",
       " 'onlin': 186,\n",
       " 'e': 280,\n",
       " 'pleas': 321,\n",
       " 's': 518,\n",
       " 'f': 88,\n",
       " 'chang': 105,\n",
       " 'how': 120,\n",
       " 'that': 433,\n",
       " 'or': 441,\n",
       " 'can': 390,\n",
       " 'peopl': 92,\n",
       " 'what': 204,\n",
       " 'much': 91,\n",
       " 'they': 132,\n",
       " '8434': 1,\n",
       " 'ani': 260,\n",
       " 'affect': 19,\n",
       " 'get': 405,\n",
       " 'eat': 15,\n",
       " 'weather': 4,\n",
       " 'nowth': 1,\n",
       " 'car': 29,\n",
       " 'environ': 18,\n",
       " 'particular': 12,\n",
       " 'climat': 4,\n",
       " 'abl': 46,\n",
       " 'technic': 9,\n",
       " 'bank': 55,\n",
       " 'connect': 40,\n",
       " 'invest': 105,\n",
       " 'act': 118,\n",
       " 'eight': 23,\n",
       " 'afford': 43,\n",
       " 'belong': 10,\n",
       " 'request': 76,\n",
       " 'cours': 26,\n",
       " '13': 28,\n",
       " '3': 379,\n",
       " 'have': 475,\n",
       " 'been': 168,\n",
       " '2': 325,\n",
       " 'adequ': 5,\n",
       " 'so': 186,\n",
       " 'around': 41,\n",
       " 'special': 184,\n",
       " 'come': 104,\n",
       " 'preced': 5,\n",
       " 'team': 26,\n",
       " '4': 243,\n",
       " 'whatsoev': 4,\n",
       " 'chairman': 11,\n",
       " 'terrorist': 6,\n",
       " 'immedi': 67,\n",
       " 'regard': 128,\n",
       " 'tax': 34,\n",
       " 'abil': 35,\n",
       " 'await': 9,\n",
       " 'understand': 55,\n",
       " 'success': 52,\n",
       " 'apex': 3,\n",
       " 'relat': 45,\n",
       " 'arrang': 23,\n",
       " 'contact': 111,\n",
       " 'throw': 7,\n",
       " 'money': 188,\n",
       " 'associ': 29,\n",
       " 'quarter': 31,\n",
       " 'unit': 72,\n",
       " 'assist': 50,\n",
       " 'some': 126,\n",
       " 'comprehens': 18,\n",
       " 'convinc': 8,\n",
       " 'propos': 21,\n",
       " 'thousand': 94,\n",
       " 'send': 137,\n",
       " 'seen': 27,\n",
       " 'subsequ': 11,\n",
       " '234': 6,\n",
       " 'hundr': 47,\n",
       " 'commenc': 8,\n",
       " 'need': 255,\n",
       " 'clarif': 2,\n",
       " 'may': 178,\n",
       " 'share': 80,\n",
       " 'explicitli': 1,\n",
       " 'well': 87,\n",
       " 'cover': 30,\n",
       " 'foreign': 33,\n",
       " 'process': 73,\n",
       " 'obligationin': 1,\n",
       " 'perceiv': 6,\n",
       " 'arous': 7,\n",
       " 'mode': 7,\n",
       " 'countri': 67,\n",
       " 'agreement': 33,\n",
       " 'committe': 9,\n",
       " 'capit': 27,\n",
       " 'opportun': 55,\n",
       " 'usd': 17,\n",
       " 'sincer': 41,\n",
       " 'govern': 51,\n",
       " 'forestal': 1,\n",
       " '000': 114,\n",
       " 'fund': 52,\n",
       " 'favor': 19,\n",
       " 'if': 355,\n",
       " 'better': 74,\n",
       " 'suspicion': 2,\n",
       " 'across': 11,\n",
       " 'owner': 50,\n",
       " 'form': 72,\n",
       " 'must': 84,\n",
       " 'confirm': 64,\n",
       " 'currenc': 3,\n",
       " 'offici': 31,\n",
       " 'receiv': 164,\n",
       " 'adam': 17,\n",
       " 'rememb': 51,\n",
       " 'upon': 41,\n",
       " 'tactic': 3,\n",
       " 'integr': 26,\n",
       " 'investig': 14,\n",
       " 'follow': 107,\n",
       " '8507': 1,\n",
       " 'mind': 42,\n",
       " 'favour': 5,\n",
       " 'run': 49,\n",
       " 'wish': 91,\n",
       " 'cabinet': 7,\n",
       " 'thirti': 9,\n",
       " 'within': 104,\n",
       " 'where': 75,\n",
       " 'holder': 6,\n",
       " 'base': 97,\n",
       " 'such': 95,\n",
       " 'person': 72,\n",
       " 'fulfil': 6,\n",
       " 'dollar': 129,\n",
       " 'from': 405,\n",
       " 'account': 115,\n",
       " 'consumm': 9,\n",
       " '00': 135,\n",
       " 'possibl': 55,\n",
       " 'fit': 14,\n",
       " 'conveni': 26,\n",
       " 'directli': 24,\n",
       " 'i': 347,\n",
       " 'exceed': 10,\n",
       " 'transfer': 52,\n",
       " 'partnership': 13,\n",
       " 'requir': 120,\n",
       " 'not': 424,\n",
       " 'million': 112,\n",
       " 'huge': 48,\n",
       " 'which': 166,\n",
       " 'busi': 134,\n",
       " 'purpos': 42,\n",
       " 'should': 140,\n",
       " 'necessari': 45,\n",
       " 'dispos': 8,\n",
       " 'do': 298,\n",
       " 'oblig': 19,\n",
       " 'incur': 13,\n",
       " 'bill': 62,\n",
       " 'whatev': 11,\n",
       " '731': 1,\n",
       " 'especi': 12,\n",
       " 'matter': 38,\n",
       " 'workabl': 2,\n",
       " 'on': 525,\n",
       " 'turn': 54,\n",
       " 'area': 64,\n",
       " 'retir': 4,\n",
       " 'reason': 77,\n",
       " 'same': 91,\n",
       " 'state': 96,\n",
       " 'man': 62,\n",
       " 'deposit': 32,\n",
       " 'project': 78,\n",
       " 'seven': 14,\n",
       " 'legal': 32,\n",
       " 'amount': 21,\n",
       " 'accordingli': 3,\n",
       " 'presidenti': 3,\n",
       " 'profit': 47,\n",
       " 'recommend': 31,\n",
       " 'drug': 98,\n",
       " 'long': 113,\n",
       " 'partner': 54,\n",
       " 'ventur': 20,\n",
       " 'most': 151,\n",
       " 'light': 23,\n",
       " 'thirteen': 3,\n",
       " 'respons': 35,\n",
       " '306': 3,\n",
       " 'reach': 47,\n",
       " '802': 7,\n",
       " 'senat': 2,\n",
       " 'initi': 26,\n",
       " 'asid': 9,\n",
       " 'involv': 60,\n",
       " 'beneficiari': 14,\n",
       " 'bear': 14,\n",
       " 'without': 134,\n",
       " 'number': 126,\n",
       " 'minim': 10,\n",
       " 'leav': 26,\n",
       " 'set': 69,\n",
       " 'loyalti': 2,\n",
       " 'enough': 34,\n",
       " 'be': 497,\n",
       " 'emphasi': 3,\n",
       " '5': 246,\n",
       " 'concern': 37,\n",
       " 'anoth': 35,\n",
       " 'intend': 75,\n",
       " 'these': 161,\n",
       " 'shall': 41,\n",
       " 'trust': 27,\n",
       " 'custodi': 8,\n",
       " 'deem': 10,\n",
       " 'discuss': 49,\n",
       " 'moment': 20,\n",
       " 'john': 14,\n",
       " 'dear': 53,\n",
       " 'moni': 3,\n",
       " 'all': 478,\n",
       " 'chosen': 4,\n",
       " 'into': 161,\n",
       " 'conceiv': 5,\n",
       " '1': 353,\n",
       " 'statu': 9,\n",
       " 'sinc': 64,\n",
       " 'provid': 136,\n",
       " 'manufactur': 24,\n",
       " '22': 41,\n",
       " 'includ': 158,\n",
       " 'sadler': 2,\n",
       " 'constru': 39,\n",
       " 'conjunct': 10,\n",
       " 'adkin': 3,\n",
       " 'further': 92,\n",
       " 'select': 71,\n",
       " 'web': 52,\n",
       " 'materi': 62,\n",
       " 'inform': 235,\n",
       " 'buy': 94,\n",
       " 'open': 53,\n",
       " 'affili': 55,\n",
       " '28': 21,\n",
       " 'dealer': 61,\n",
       " 'offer': 259,\n",
       " 'disclaim': 12,\n",
       " 'silicon': 2,\n",
       " 'cola': 4,\n",
       " 'motor': 7,\n",
       " 'speedway': 1,\n",
       " 'com': 445,\n",
       " 'nascar': 4,\n",
       " 'detail': 124,\n",
       " 'int': 5,\n",
       " '08': 28,\n",
       " 'investor': 57,\n",
       " 'mbna': 1,\n",
       " 'risk': 74,\n",
       " 'chrome': 2,\n",
       " 'parti': 75,\n",
       " 'track': 30,\n",
       " 'otcbb': 19,\n",
       " 'report': 99,\n",
       " 'profil': 54,\n",
       " 'pick': 27,\n",
       " 'potenti': 38,\n",
       " 'nashvil': 4,\n",
       " 'trace': 14,\n",
       " '300': 51,\n",
       " 'relianc': 25,\n",
       " 'locat': 46,\n",
       " 'determin': 18,\n",
       " 'caus': 72,\n",
       " 'instal': 20,\n",
       " 'corp': 28,\n",
       " 'actual': 62,\n",
       " 'contain': 77,\n",
       " 'exclus': 41,\n",
       " 'america': 47,\n",
       " 'inc': 82,\n",
       " 'upgrad': 14,\n",
       " 'releas': 69,\n",
       " 'agre': 28,\n",
       " 'stop': 154,\n",
       " 'venu': 2,\n",
       " 'regist': 68,\n",
       " 'blank': 30,\n",
       " 'those': 72,\n",
       " 'simulutor': 1,\n",
       " '05': 30,\n",
       " 'fundrais': 4,\n",
       " 'driver': 12,\n",
       " '02': 22,\n",
       " 'simul': 2,\n",
       " 'speedpark': 1,\n",
       " 'highlight': 7,\n",
       " 'annual': 33,\n",
       " 'compani': 147,\n",
       " '30': 95,\n",
       " 'chapin': 1,\n",
       " 'year': 134,\n",
       " 'host': 23,\n",
       " '14': 53,\n",
       " 'opinion': 42,\n",
       " 'third': 69,\n",
       " 'mill': 5,\n",
       " 'champion': 7,\n",
       " 'demand': 29,\n",
       " '01': 46,\n",
       " 'uncertainti': 49,\n",
       " 'fame': 2,\n",
       " '2003': 54,\n",
       " '19': 50,\n",
       " 'email': 297,\n",
       " 'complet': 100,\n",
       " 'stock': 100,\n",
       " 'renew': 13,\n",
       " 'publish': 55,\n",
       " 'see': 146,\n",
       " 'about': 209,\n",
       " 'broker': 31,\n",
       " 'look': 191,\n",
       " 'expand': 26,\n",
       " 'import': 61,\n",
       " 'nation': 37,\n",
       " 'row': 10,\n",
       " 'specul': 33,\n",
       " 'announc': 63,\n",
       " 'now': 275,\n",
       " 'boost': 25,\n",
       " 'stud': 7,\n",
       " 'thumb': 1,\n",
       " 'liabil': 6,\n",
       " 'quarterli': 3,\n",
       " 'consid': 81,\n",
       " 'accept': 71,\n",
       " '07': 12,\n",
       " 'go': 190,\n",
       " 'five': 32,\n",
       " 'highli': 32,\n",
       " 'sign': 47,\n",
       " 'media': 22,\n",
       " 'file': 58,\n",
       " 'result': 131,\n",
       " 'extens': 13,\n",
       " 'solicit': 50,\n",
       " '600': 18,\n",
       " 'public': 82,\n",
       " 'unsub': 7,\n",
       " 'market': 115,\n",
       " 'own': 101,\n",
       " 'race': 6,\n",
       " '17': 58,\n",
       " 'moscow': 3,\n",
       " 'center': 35,\n",
       " 'develop': 73,\n",
       " 'event': 59,\n",
       " '03': 28,\n",
       " 'star': 23,\n",
       " 'sbr': 1,\n",
       " '27': 60,\n",
       " 'forward': 78,\n",
       " 'luncheon': 3,\n",
       " 'plan': 60,\n",
       " 'side': 42,\n",
       " 'make': 160,\n",
       " 'ad': 61,\n",
       " 'custom': 104,\n",
       " 'baldacci': 1,\n",
       " 'realist': 5,\n",
       " 'oper': 91,\n",
       " 'upper': 5,\n",
       " 'tn': 3,\n",
       " 'servic': 137,\n",
       " 'notic': 96,\n",
       " 'intellig': 17,\n",
       " '24': 82,\n",
       " 'ppkkqpkgimzpx': 1,\n",
       " 'owe': 11,\n",
       " 'onli': 306,\n",
       " 'motorsport': 1,\n",
       " '04': 25,\n",
       " 'two': 92,\n",
       " 'advisor': 41,\n",
       " 'expans': 11,\n",
       " 'believ': 105,\n",
       " 'sell': 72,\n",
       " 'nadeau': 1,\n",
       " 'gener': 132,\n",
       " 'subsidiari': 8,\n",
       " 'st': 65,\n",
       " 'circul': 20,\n",
       " 'indianapoli': 2,\n",
       " 'sale': 111,\n",
       " '09': 16,\n",
       " 'lineup': 1,\n",
       " 'sec': 27,\n",
       " 'differ': 92,\n",
       " 'canneri': 2,\n",
       " 'forth': 21,\n",
       " 'burrough': 2,\n",
       " '12': 89,\n",
       " 'entertain': 31,\n",
       " 'coca': 4,\n",
       " 'press': 58,\n",
       " 'imt': 1,\n",
       " 'california': 13,\n",
       " 'opri': 1,\n",
       " 'give': 106,\n",
       " 'monterey': 3,\n",
       " 'intern': 83,\n",
       " 'ink': 8,\n",
       " 'aris': 7,\n",
       " 'racer': 1,\n",
       " 'world': 128,\n",
       " 'use': 236,\n",
       " 'recent': 56,\n",
       " 'statement': 62,\n",
       " 'unless': 15,\n",
       " 'superspeedway': 1,\n",
       " 'isp': 4,\n",
       " 'loui': 13,\n",
       " 'among': 25,\n",
       " 'pcr': 1,\n",
       " 'small': 47,\n",
       " 'zupymv': 1,\n",
       " 'mail': 193,\n",
       " 'exit': 4,\n",
       " 'emerg': 29,\n",
       " 'llrwi': 1,\n",
       " 'addit': 66,\n",
       " 'j': 24,\n",
       " 'tfntye': 1,\n",
       " 'cap': 29,\n",
       " 'dvafv': 1,\n",
       " 'gtlaisyeviobdf': 1,\n",
       " 'oesxpzuf': 1,\n",
       " 'updi': 1,\n",
       " 'pzyvktpipwcmjc': 1,\n",
       " 'batteri': 13,\n",
       " 'patch': 18,\n",
       " 'sat': 20,\n",
       " '_': 140,\n",
       " 'even': 111,\n",
       " 'burp': 5,\n",
       " 'spank': 1,\n",
       " '9': 110,\n",
       " '45': 39,\n",
       " 'viriiiti': 1,\n",
       " 'ess': 6,\n",
       " 'charg': 52,\n",
       " 'qq': 3,\n",
       " 't': 318,\n",
       " 'wa': 193,\n",
       " 'technolog': 87,\n",
       " 'men': 60,\n",
       " 'er': 13,\n",
       " 'o': 157,\n",
       " '99045': 1,\n",
       " 'm': 159,\n",
       " 'othersim': 1,\n",
       " 'ini': 2,\n",
       " 'g': 92,\n",
       " 'classnu': 1,\n",
       " 'imagin': 18,\n",
       " 'lgger': 1,\n",
       " 'yourself': 64,\n",
       " 'like': 212,\n",
       " 'y': 80,\n",
       " '311': 3,\n",
       " '55': 28,\n",
       " 'ore': 5,\n",
       " '8': 170,\n",
       " 'x': 107,\n",
       " 'class': 13,\n",
       " 'oj': 1,\n",
       " '31': 30,\n",
       " '990': 3,\n",
       " '442': 1,\n",
       " '384': 1,\n",
       " 'dermal': 2,\n",
       " 'othersxl': 1,\n",
       " 'loo': 14,\n",
       " '6': 170,\n",
       " 'wi': 26,\n",
       " 'jk': 1,\n",
       " 'n': 146,\n",
       " 'listr': 1,\n",
       " 'alr': 1,\n",
       " '822': 1,\n",
       " 'vym': 1,\n",
       " 'never': 76,\n",
       " '44': 10,\n",
       " 'befor': 132,\n",
       " 'oney': 3,\n",
       " 'th': 121,\n",
       " 'jkr': 1,\n",
       " 'sky': 12,\n",
       " 'soar': 17,\n",
       " 'want': 226,\n",
       " '60': 99,\n",
       " 'gosj': 1,\n",
       " 'ni': 5,\n",
       " 'fj': 1,\n",
       " 'b': 157,\n",
       " 'qjl': 1,\n",
       " 'xl': 8,\n",
       " '99442': 1,\n",
       " '218': 4,\n",
       " '96': 12,\n",
       " 'day': 158,\n",
       " 'dd': 4,\n",
       " 'tor': 11,\n",
       " 'doc': 6,\n",
       " 'lessli': 1,\n",
       " 'rocket': 8,\n",
       " 'isfi': 1,\n",
       " 'lov': 1,\n",
       " 'other': 212,\n",
       " 'r': 197,\n",
       " 'who': 127,\n",
       " '32': 33,\n",
       " 'icker': 1,\n",
       " 'l': 110,\n",
       " 'innu': 1,\n",
       " 'che': 6,\n",
       " 'then': 95,\n",
       " 'nfj': 1,\n",
       " 'super': 59,\n",
       " 'atch': 1,\n",
       " 'h': 108,\n",
       " 'oolz': 1,\n",
       " 'libido': 2,\n",
       " 'roven': 1,\n",
       " 'ment': 10,\n",
       " 'w': 76,\n",
       " 'bac': 3,\n",
       " 'xual': 9,\n",
       " 'effort': 49,\n",
       " 'en': 23,\n",
       " 'ight': 2,\n",
       " 'othersi': 1,\n",
       " '39': 22,\n",
       " 'gigccb': 1,\n",
       " 'design': 63,\n",
       " 'bb': 12,\n",
       " 'erget': 1,\n",
       " '36': 55,\n",
       " 'enlarg': 26,\n",
       " 'p': 139,\n",
       " 'k': 70,\n",
       " 'work': 192,\n",
       " 'pillz': 1,\n",
       " 're': 205,\n",
       " '7': 218,\n",
       " 'size': 90,\n",
       " 'today': 179,\n",
       " '831': 1,\n",
       " 'lj': 2,\n",
       " 'ri': 10,\n",
       " 'first': 97,\n",
       " 'good': 116,\n",
       " 'wcwknoanopkt': 1,\n",
       " 'admiss': 1,\n",
       " 'bmw': 7,\n",
       " 'wash': 3,\n",
       " 'best': 228,\n",
       " 'homepag': 4,\n",
       " 'last': 126,\n",
       " 'pleasant': 2,\n",
       " 'mess': 2,\n",
       " 'eilao': 2,\n",
       " 'discontinu': 4,\n",
       " '100': 153,\n",
       " 'galleri': 3,\n",
       " 'morn': 27,\n",
       " 'volkswagen': 2,\n",
       " 'test': 35,\n",
       " 'distress': 4,\n",
       " 'frank': 6,\n",
       " 'hard': 59,\n",
       " 'trant': 1,\n",
       " 'miracul': 3,\n",
       " 'mailto': 11,\n",
       " 'her': 61,\n",
       " 'shop': 46,\n",
       " 'wonder': 21,\n",
       " 'excel': 18,\n",
       " 'udtih': 1,\n",
       " '99': 74,\n",
       " 'snapshot': 4,\n",
       " 'grati': 3,\n",
       " 'choos': 41,\n",
       " 'maria': 4,\n",
       " 'sara': 3,\n",
       " 'honda': 2,\n",
       " 'video': 53,\n",
       " 'theme': 5,\n",
       " 'paliourg': 84,\n",
       " 'cambel': 1,\n",
       " 'photograph': 3,\n",
       " 'support': 52,\n",
       " 'ua': 3,\n",
       " 'free': 210,\n",
       " 'aduit': 1,\n",
       " 'deliv': 52,\n",
       " 'ocd': 3,\n",
       " 'serv': 22,\n",
       " 'hour': 102,\n",
       " 'qualifi': 30,\n",
       " 'doe': 82,\n",
       " 'site': 132,\n",
       " 'znuljd': 1,\n",
       " 'stand': 25,\n",
       " 'levitra': 17,\n",
       " 'dakar': 1,\n",
       " 'altern': 26,\n",
       " 'vthrd': 1,\n",
       " 'anbmdtzjqu': 1,\n",
       " 'right': 103,\n",
       " 'viagara': 1,\n",
       " 'stiffnesspizzeria': 1,\n",
       " 'pill': 84,\n",
       " 'hot': 53,\n",
       " 'item': 15,\n",
       " 'ym': 2,\n",
       " 'minut': 64,\n",
       " 'disordersidiosyncrat': 1,\n",
       " 'prozac': 27,\n",
       " 'fatsrhombu': 1,\n",
       " 'unknown': 10,\n",
       " 'effect': 100,\n",
       " 'pay': 95,\n",
       " 'join': 32,\n",
       " 'insur': 17,\n",
       " 'lipitor': 13,\n",
       " 'let': 71,\n",
       " 'current': 95,\n",
       " 'cure': 8,\n",
       " 'avail': 184,\n",
       " 'wast': 21,\n",
       " 'diqb': 1,\n",
       " 'reliev': 10,\n",
       " 'tire': 23,\n",
       " 'hairlosschos': 1,\n",
       " 'rx': 42,\n",
       " 'incombust': 1,\n",
       " 'help': 106,\n",
       " 'dont': 15,\n",
       " 'ncl': 1,\n",
       " 'known': 49,\n",
       " 'hassl': 22,\n",
       " 'suffer': 13,\n",
       " 'eloqu': 1,\n",
       " 'offic': 150,\n",
       " 'popular': 46,\n",
       " 'visit': 141,\n",
       " 'wiley': 2,\n",
       " 'spasm': 1,\n",
       " 'depress': 39,\n",
       " 'nexium': 7,\n",
       " 'name': 107,\n",
       " 'heartburnfirewood': 1,\n",
       " 'propecia': 14,\n",
       " 'manor': 1,\n",
       " 'carri': 42,\n",
       " 'viagraaugustin': 1,\n",
       " 'treatment': 33,\n",
       " 'real': 85,\n",
       " 'trial': 18,\n",
       " 'briababhdpr': 1,\n",
       " 'cbywdvdthl': 1,\n",
       " 'inch': 37,\n",
       " 'rlaegydzfb': 1,\n",
       " 'add': 44,\n",
       " 'brand': 78,\n",
       " 'purchas': 58,\n",
       " 'ter': 2,\n",
       " 'ylbafsepgjv': 1,\n",
       " 'limit': 94,\n",
       " 'back': 127,\n",
       " 'yhvqbvdboevkcd': 1,\n",
       " 'frdjvdbesk': 1,\n",
       " 'guarante': 93,\n",
       " 'warranti': 12,\n",
       " 'igjohodzauuuu': 1,\n",
       " 'nogsvvbnwug': 1,\n",
       " 'bottl': 12,\n",
       " 'fxbekdcaolk': 1,\n",
       " 'gsiaagcrhyp': 1,\n",
       " 'ize': 3,\n",
       " 'cdpizacqjkufx': 1,\n",
       " 'sure': 38,\n",
       " 'satisfi': 24,\n",
       " 'learn': 49,\n",
       " 'eqiupgbbaxz': 1,\n",
       " 'solut': 76,\n",
       " 'gogqkkdpbdo': 1,\n",
       " 'pe': 7,\n",
       " 'xxieqncfpa': 1,\n",
       " 'peni': 33,\n",
       " 'check': 92,\n",
       " 'out': 270,\n",
       " 'mat': 2,\n",
       " 'wdyiwpbqipv': 1,\n",
       " 'yreliodctrin': 1,\n",
       " 'hfkosxcymgftzd': 1,\n",
       " 'prove': 21,\n",
       " 'woodyard': 1,\n",
       " 'oligarchi': 4,\n",
       " 'mania': 1,\n",
       " 'acryl': 5,\n",
       " 'bam': 3,\n",
       " 'coffey': 3,\n",
       " 'cheer': 7,\n",
       " 'welsh': 2,\n",
       " 'auxiliari': 4,\n",
       " 'condit': 39,\n",
       " 'abomin': 3,\n",
       " 'tetrachlorid': 2,\n",
       " 'ballard': 2,\n",
       " 'canadian': 11,\n",
       " 'china': 18,\n",
       " 'ferret': 3,\n",
       " 'woodland': 4,\n",
       " 'cabl': 25,\n",
       " 'els': 20,\n",
       " 'cloister': 1,\n",
       " 'shut': 4,\n",
       " 'quak': 1,\n",
       " 'dabbl': 2,\n",
       " 'tv': 21,\n",
       " 'giblet': 2,\n",
       " 'segovia': 1,\n",
       " 'daphn': 2,\n",
       " 'decad': 15,\n",
       " 'contigu': 2,\n",
       " 'rdd': 1,\n",
       " 'seduct': 3,\n",
       " 'ligament': 1,\n",
       " 'annett': 6,\n",
       " 'trauma': 1,\n",
       " 'elaps': 1,\n",
       " 'servomechan': 1,\n",
       " 'ornat': 1,\n",
       " 'desol': 1,\n",
       " 'clubroom': 1,\n",
       " 'derid': 3,\n",
       " 'synapt': 1,\n",
       " 'gnaw': 1,\n",
       " 'yaqui': 2,\n",
       " 'charli': 6,\n",
       " 'byroad': 6,\n",
       " 'leadsman': 1,\n",
       " 'almighti': 2,\n",
       " 'canopi': 4,\n",
       " 'iturean': 1,\n",
       " 'sequestr': 2,\n",
       " 'cambric': 5,\n",
       " 'diagnostician': 1,\n",
       " 'befog': 4,\n",
       " 'alexand': 5,\n",
       " 'emphysemat': 1,\n",
       " 'lie': 24,\n",
       " 'bookcas': 3,\n",
       " 'crack': 9,\n",
       " 'stacey': 1,\n",
       " 'becaus': 98,\n",
       " 'week': 99,\n",
       " 'everyth': 44,\n",
       " 'rich': 17,\n",
       " 've': 93,\n",
       " 'system': 121,\n",
       " 'autom': 14,\n",
       " 'text': 75,\n",
       " 'per': 78,\n",
       " 'parallelogram': 2,\n",
       " 'show': 74,\n",
       " 'opt': 21,\n",
       " 'random': 6,\n",
       " 'code': 28,\n",
       " 'worldwid': 57,\n",
       " 'adv': 6,\n",
       " 'amaz': 25,\n",
       " 'sever': 37,\n",
       " 'www': 263,\n",
       " 'html': 85,\n",
       " 'link': 150,\n",
       " 'huh': 1,\n",
       " 'dislik': 7,\n",
       " 'wwwbargin': 1,\n",
       " 'below': 115,\n",
       " 'cheap': 65,\n",
       " 'viagra': 94,\n",
       " 'oxygen': 4,\n",
       " 'http': 475,\n",
       " 'price': 297,\n",
       " 'erect': 49,\n",
       " 'second': 70,\n",
       " '20': 133,\n",
       " 'vroooom': 2,\n",
       " 'easi': 87,\n",
       " 'quit': 30,\n",
       " 'enjoy': 43,\n",
       " 'overdr': 2,\n",
       " 'biz': 68,\n",
       " 'place': 96,\n",
       " 'ebay': 10,\n",
       " '45954036': 1,\n",
       " 'clk': 1,\n",
       " 'softwar': 109,\n",
       " 'feder': 68,\n",
       " 'userid': 2,\n",
       " 'express': 61,\n",
       " 'clile': 1,\n",
       " 'friend': 55,\n",
       " 'fortun': 21,\n",
       " 'turnkey': 6,\n",
       " 'turori': 2,\n",
       " 'fedex': 10,\n",
       " '56075519': 1,\n",
       " 'januari': 34,\n",
       " 'ere': 4,\n",
       " 'zd': 1,\n",
       " 'backyardkati': 1,\n",
       " 'earn': 40,\n",
       " 'anymor': 7,\n",
       " 'discr': 1,\n",
       " 'mll': 1,\n",
       " 'v': 139,\n",
       " 'ife': 1,\n",
       " 'leas': 10,\n",
       " 'action': 77,\n",
       " 'backyard': 2,\n",
       " 'crk': 1,\n",
       " '219': 3,\n",
       " 'bggv': 1,\n",
       " 'onfidenti': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_sum_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overlap(dict1, dict2):\n",
    "    \"\"\"\n",
    "    Find the overlapping dictionaries\n",
    "    \"\"\"\n",
    "    key1 = set(dict1.keys())\n",
    "    key2 = set(dict2.keys())\n",
    "    intersection = key1 & key2\n",
    "    newdict1 = {}\n",
    "    newdict2 = {}\n",
    "    intersection = list(intersection)\n",
    "    ninter = len(intersection)\n",
    "    for i in range(ninter):\n",
    "        newdict1[intersection[i]] = dict1[intersection[i]]\n",
    "        newdict2[intersection[i]] = dict2[intersection[i]]\n",
    "    return newdict1, newdict2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ovlp_spam, ovlp_ham = overlap(spam_bag, ham_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a= ovlp_spam.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Naive_Bayes(test, train):\n",
    "    \"\"\"\n",
    "    Compute the score of test with respect to training sets using Naive Bayes\n",
    "    \n",
    "    Returns to scores\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def NN_Distances(test, train, nn_option='L2'):\n",
    "    \"\"\"\n",
    "    Compute the distance of test based on training sets using Nearest Neighbor\n",
    "    test: test [one_email] ; one(training set 1 [list]); two(training set 2 [list])\n",
    "    \n",
    "    Returns to the array of distances\n",
    "    \"\"\"\n",
    "    testing = embed_one(test)[0] ## because it's just one\n",
    "    testkeys = testing.keys()\n",
    "    ntest = len(testkeys)\n",
    "\n",
    "    ntrain = len(train)\n",
    "    dist = np.zeros(ntrain)\n",
    "    \n",
    "    for i in range(ntrain):\n",
    "        onekey = train[i].keys()\n",
    "        one_eval = testing.copy()\n",
    "        one_eval.update(train[i]) ## for all un-matching dictionaries\n",
    "        for j in range(ntest):\n",
    "            if list(testkeys)[j] in onekey:\n",
    "                thiskey = list(testkeys)[j]\n",
    "                one_eval[thiskey] = train[i][thiskey] - testing[thiskey] ## subtract only when items are matching\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        one_eval = np.array(list(one_eval.values()))\n",
    "        print (one_eval)\n",
    "        if option == 'L1' or option == 'Linf':\n",
    "            dist[i] = sum(np.abs(one_eval))\n",
    "        elif option == 'L2':\n",
    "            dist[i] = np.sqrt(sum(one_eval**2))\n",
    "            \n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Naive Bayes, Decision Tree, NN Classifiers\n",
    "def Classifier(new, one, two, option='NB', nn_option='L2'):\n",
    "    \"\"\"\n",
    "    For \"overlapping\" bag of words between new and training sets, evaluate probability based on classifier of choice\n",
    "    NB: Naive Bayes; DT: Decision Tree; NN: Nearest Neighbors\n",
    "    New (to-be-examined); one(training 1); two(training 2)\n",
    "    \"\"\"\n",
    "    \n",
    "    common_new, common_one = overlap(new, one)\n",
    "    \n",
    "    ckeys = common\n",
    "    ncommon = len(common)\n",
    "    \n",
    "    scores = np.zeros(2)\n",
    "    if option == 'NN':\n",
    "        dist_one = NN_Distances(new, one, nn_option)\n",
    "        dist_two = NN_Distances(new, two, nn_option)\n",
    "        if nn_option == 'L1' or nn_option == 'L2':\n",
    "            scores[0] = np.sum(dist_one)\n",
    "            scores[1] = np.sum(dist_two)\n",
    "        elif nn_option == 'Linf':\n",
    "            scores[0] = np.max(dist_one)\n",
    "            scores[1] = np.max(dist_two)\n",
    "    \n",
    "    elif option == 'NB':\n",
    "        \n",
    "            \n",
    "    elif option == 'DT':\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### only evaluate the overlapping keywords?\n",
    "inter_spam, inter_ham = overlap(spam_bag, ham_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INCORRECT (Without Stemming)\n",
    "def embed_whole(datalist):\n",
    "    \"\"\"\n",
    "    From a list of data (should have multiple), do stemming (+remove non-words) then apply the bag-of-words model\n",
    "    \n",
    "    Returns\n",
    "    a dictionary of bag-of-words each dic corresponding to its counts\n",
    "    \"\"\"\n",
    "    bag = {}\n",
    "    ndata = len(datalist)\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    for i in range(ndata):\n",
    "        stemmed = tokenizer.tokenize(datalist[i])\n",
    "        nstem = len(stemmed)\n",
    "        for j in range(nstem):\n",
    "            key = stemmed[j]\n",
    "            if key in bag:\n",
    "                bag[key] += 1\n",
    "            else:\n",
    "                bag[key] = 1        \n",
    "    return bag\n",
    "\n",
    "def embed_one(datalist):\n",
    "    \"\"\"\n",
    "    Construct stemmed+bag-of-words model for individual then construct an array of individual bags\n",
    "    \n",
    "    Returns\n",
    "    a collection of individual set dict corresponding to its counts\n",
    "    \"\"\"\n",
    "    bag_collection = []\n",
    "    ndata = len(datalist)\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    for i in range(ndata):\n",
    "        one_bag = {}\n",
    "        stemmed = tokenizer.tokenize(datalist[i])\n",
    "        nstem = len(stemmed)\n",
    "        for j in range(nstem):\n",
    "            key = stemmed[j]\n",
    "            if key in one_bag:\n",
    "                one_bag[key] += 1\n",
    "            else:\n",
    "                one_bag[key] = 1\n",
    "        bag_collection.append(one_bag)\n",
    "        \n",
    "    return bag_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
