{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm \n",
    "from scipy.stats import bernoulli\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "\n",
    "kDim = 6 # the number of dimension\n",
    "# kUsers = 610 # 610 is total, but we use 300 users \n",
    "# kMovies = 9724 # 9724 is total, but we use 6000 movies\n",
    "\n",
    "# These data are used to draw a kDim-vector that follows Gaussian Distribution (kMean, kCov)\n",
    "kMean = []\n",
    "for i in range(kDim):\n",
    "    kMean.append(0)\n",
    "kCov = 0.1 * np.identity(n=kDim,dtype='float')\n",
    "\n",
    "# Rating matrix, which is sparsew\n",
    "gR = dict() # Key = (userId, movieId)\n",
    "gD = dict() # Key = (userId, moveId) value = existence\n",
    "gU = dict() # Key = (userId), value = user vector\n",
    "gV = dict() # Key = (movieId), value = movie vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all model variables reading given file(csv)\n",
    "# It should be executed first before calling MakeTestSet which split the whole file into \n",
    "# training file and test file\n",
    "def GenerateModelVariables (in_file_name, in_U, in_V):\n",
    "    file = open(in_file_name, 'r')\n",
    "    fileReader = csv.reader(file)\n",
    "    \n",
    "    for row in fileReader:\n",
    "        if row[0] == 'userId':\n",
    "            continue\n",
    "        else:\n",
    "            currentUserID = int(row[0])\n",
    "            currentMovieID = int(row[1])\n",
    "            currentRating = float(row[2])\n",
    "\n",
    "            if type(in_U.get(currentUserID)) == type(None):\n",
    "                in_U[currentUserID] = np.random.multivariate_normal(kMean, kCov, 1).T\n",
    "            if type(gV.get(currentMovieID)) == type(None):\n",
    "                in_V[currentMovieID] = np.random.multivariate_normal(kMean, kCov, 1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test set... from given training file\n",
    "def MakeTestSet(in_file_name, in_ratio, out_trainingFileName, out_testFileName):\n",
    "    originalFile = open(in_file_name, 'r')\n",
    "    fileReader = csv.reader(originalFile)\n",
    "    \n",
    "    trainingFile = open(out_trainingFileName,'w')\n",
    "    testFile = open(out_testFileName, 'w')\n",
    "    \n",
    "    trainingCSVWriter = csv.writer(trainingFile, delimiter=',',quotechar=',', quoting=csv.QUOTE_MINIMAL)\n",
    "    testCSVWriter = csv.writer(testFile, delimiter=',',quotechar=',', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    trainingCSVWriter.writerow(['userId', 'movieId', 'rating'])\n",
    "    testCSVWriter.writerow(['userId', 'movieId', 'rating'])\n",
    "    \n",
    "    for row in fileReader:\n",
    "        if row[0] == 'userId':\n",
    "            continue\n",
    "        else:\n",
    "            bTrainingSet = bernoulli.rvs(in_ratio, size = 1)[0] # 1 indicates training data\n",
    "            if bTrainingSet == 1:\n",
    "                trainingCSVWriter.writerow([row[0], row[1], row[2]])\n",
    "            else:\n",
    "                testCSVWriter.writerow([row[0], row[1], row[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training file\n",
    "# This function extract all information on the set of given ratings and existence\n",
    "def ReadTrainingCSVFile(in_file_name, out_D, out_R):\n",
    "    training_file = open(in_file_name, 'r')\n",
    "    fileReader = csv.reader(training_file)\n",
    "    \n",
    "    for row in fileReader:\n",
    "        if row[0] == 'userId':\n",
    "            continue\n",
    "        else:            \n",
    "            currentUserID = int(row[0])\n",
    "            currentMovieID = int(row[1])\n",
    "            currentRating = float(row[2])\n",
    "                        \n",
    "            out_D[(currentUserID, currentMovieID)] = 1\n",
    "            out_R[(currentUserID, currentMovieID)] = currentRating\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is used to verify that the objective function is minimizing\n",
    "def CalculateJointLikelihood(in_R, in_U, in_V, in_D):\n",
    "    \n",
    "    logLikelihood = 0.0\n",
    "    \n",
    "    for eachKey in in_D.keys():\n",
    "        logLikelihood = logLikelihood + ((in_R[eachKey] - (in_U[eachKey[0]].T @ in_V[eachKey[1]])) ** 2)\n",
    "    \n",
    "    return logLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We solve this problem iteratively. \n",
    "# For example, first set all U, V = 0\n",
    "#\n",
    "# For the first iteration:\n",
    "# Calculate U using given V\n",
    "# Next, \n",
    "# Calculate V using calculated U above.\n",
    "\n",
    "def CalculateMLE(in_init_U, in_init_V, in_D, in_R, in_nIterations):\n",
    "    \n",
    "    U = copy.deepcopy(in_init_U) # init U\n",
    "    V = copy.deepcopy(in_init_V) # init V\n",
    "    \n",
    "    for t in range(in_nIterations):\n",
    "        for i in U.keys():\n",
    "            firstTerm = np.zeros([kDim, kDim], float)\n",
    "            secondTerm = np.zeros([kDim, 1], float)\n",
    "\n",
    "            for j in V.keys():\n",
    "                if type(in_D.get((i,j))) != type(None):\n",
    "                    \n",
    "                    firstTerm = firstTerm + (V[j] @ V[j].T)\n",
    "                    secondTerm = secondTerm + (in_R[(i, j)] * V[j])\n",
    "            \n",
    "            U[i] = np.linalg.pinv(firstTerm) @ secondTerm\n",
    "\n",
    "        for j in V.keys():\n",
    "            firstTerm = np.zeros([kDim, kDim], float)\n",
    "            secondTerm = np.zeros([kDim, 1], float)\n",
    "\n",
    "            for i in U.keys():\n",
    "                if type(in_D.get((i,j))) != type(None):\n",
    "                    \n",
    "                    firstTerm = firstTerm + (U[i] @ U[i].T)\n",
    "                    secondTerm = secondTerm + (in_R[(i, j)] * U[i])\n",
    "            \n",
    "            V[j] = np.linalg.pinv(firstTerm) @ secondTerm\n",
    "        \n",
    "        # calculate current joint likelihood\n",
    "        currentLikelihood = CalculateJointLikelihood(in_D=gD, in_R= gR, in_U=U, in_V=V)\n",
    "        \n",
    "        # Show the current value of objective function\n",
    "        print(\"Value => \", currentLikelihood)\n",
    "        \n",
    "    return U, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSample_UV(in_init_U, in_init_V, in_R, in_D, in_nSamples, in_stepSize):\n",
    "    \n",
    "    U = copy.deepcopy(in_init_U) # init U\n",
    "    V = copy.deepcopy(in_init_V) # init V\n",
    "    \n",
    "    nUsers = len(U)\n",
    "    nMovies = len(V)\n",
    "    c = 1.0\n",
    "    \n",
    "    u_samples = []\n",
    "    v_samples = []\n",
    "    \n",
    "    for n in range(in_nSamples):\n",
    "        for t in range(in_stepSize):\n",
    "            print(\"iteration => \", t)\n",
    "            for i in U.keys():\n",
    "                firstTerm = np.identity(n=kDim,dtype='float') / c\n",
    "                secondTerm = np.zeros([kDim,1],dtype='float')\n",
    "\n",
    "                for j in V.keys():\n",
    "                    if type(in_D.get((i,j))) != type(None):\n",
    "                        firstTerm = firstTerm + (V[j] @ V[j].T)\n",
    "                        secondTerm = secondTerm + (in_R[(i, j)] * V[j])\n",
    "\n",
    "                covTerm = np.linalg.inv(firstTerm)\n",
    "                muTerm = (covTerm @ secondTerm).T\n",
    "\n",
    "                U[i] = np.random.multivariate_normal(muTerm[0], covTerm, 1).T\n",
    "\n",
    "            for j in V.keys():\n",
    "                firstTerm = np.identity(n=kDim,dtype='float') / c\n",
    "                secondTerm = np.zeros([kDim,1],dtype='float')\n",
    "\n",
    "                for i in U.keys():\n",
    "                    if type(in_D.get((i,j))) != type(None):\n",
    "\n",
    "                        firstTerm = firstTerm + (U[i] @ U[i].T)\n",
    "                        secondTerm = secondTerm + (in_R[(i, j)] * U[i])\n",
    "\n",
    "                covTerm = np.linalg.inv(firstTerm)\n",
    "                muTerm = (covTerm @ secondTerm).T\n",
    "\n",
    "                V[j] = np.random.multivariate_normal(muTerm[0], covTerm, 1).T\n",
    "        \n",
    "        print(\"We've got one sample from full posterior distribution\")\n",
    "        u_samples.append(U)\n",
    "        v_samples.append(V)\n",
    "    return u_samples,v_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMSETestError(in_testSetFileName, in_predRating):\n",
    "    test_file = open(in_testSetFileName, 'r')\n",
    "    fileReader = csv.reader(test_file)\n",
    "    \n",
    "    squaredErrorList = []\n",
    "    \n",
    "    for row in fileReader:\n",
    "        if row[0] == 'userId':\n",
    "            continue\n",
    "        else:\n",
    "            currentUserID = int(row[0])\n",
    "            currentMovieID = int(row[1])\n",
    "            currentRating = float(row[2])\n",
    "                \n",
    "            squaredErrorList.append((in_predRating[(currentUserID, currentMovieID)] - currentRating) ** 2 )\n",
    "            \n",
    "    return squaredErrorList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict ratings using Gibbs sampling.\n",
    "# This return predicted_ratings\n",
    "def GetRatingMatrixUsingGibbs(in_D, in_R, in_init_U, in_init_V, in_nSamples):    \n",
    "    \n",
    "    USamples, VSamples = GetSample_UV(in_D=in_D,\n",
    "                                      in_R=in_R,\n",
    "                                      in_init_U=in_init_U,\n",
    "                                      in_init_V=in_init_V,\n",
    "                                      in_nSamples=in_nSamples,\n",
    "                                      in_stepSize=10)\n",
    "    predicted_ratings = dict()\n",
    "\n",
    "    for i in in_init_U.keys():\n",
    "        for j in in_init_V.keys():\n",
    "            sum = 0.0\n",
    "            for n in range(in_nSamples):\n",
    "                sum = sum + USamples[n][i].T @ VSamples[n][j]\n",
    "            \n",
    "            predicted_ratings[(i,j)] = sum / float(in_nSamples)\n",
    "    \n",
    "    return predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllErrors_GibbsVersion(in_testFileName, in_D, in_R, in_init_U, in_init_V, in_nSamples):\n",
    "    \n",
    "    USamples, VSamples = GetSample_UV(in_D=in_D,\n",
    "                                      in_R=in_R,\n",
    "                                      in_init_U=in_init_U,\n",
    "                                      in_init_V=in_init_V,\n",
    "                                      in_nSamples=in_nSamples,\n",
    "                                      in_stepSize=10)\n",
    "    \n",
    "    trainingSquaredErrorSum = 0.0\n",
    "    testSquaredErrorSum = 0.0\n",
    "    \n",
    "    ##### training error\n",
    "    for eachKey in in_D.keys():\n",
    "        sum = 0.0\n",
    "        for n in range(in_nSamples):\n",
    "            sum = sum + USamples[n][eachKey[0]].T @ VSamples[n][eachKey[1]]\n",
    "        sum = sum / float(in_nSamples)\n",
    "        trainingSquaredErrorSum = trainingSquaredErrorSum + ((in_R[eachKey] - sum) ** 2)\n",
    "    \n",
    "    trainingSquaredErrorSum = trainingSquaredErrorSum / len(gR)\n",
    "    print('Training Error (Gibbs)', trainingSquaredErrorSum)\n",
    "    \n",
    "    #### test error\n",
    "    test_file = open(in_testFileName, 'r')\n",
    "    fileReader = csv.reader(test_file)\n",
    "    \n",
    "    testSquaredErrorSum = 0.0\n",
    "    testSetCount = 0\n",
    "    for row in fileReader:\n",
    "        if row[0] == 'userId':\n",
    "            continue\n",
    "        else:\n",
    "            testSetCount = testSetCount + 1\n",
    "            currentUserID = int(row[0])\n",
    "            currentMovieID = int(row[1])\n",
    "            currentRating = float(row[2])\n",
    "                \n",
    "            sum = 0.0\n",
    "            for n in range(in_nSamples):\n",
    "                sum = sum + USamples[n][currentUserID].T @ VSamples[n][currentMovieID]\n",
    "            estimatedRating = sum / float(in_nSamples)\n",
    "            \n",
    "            testSquaredErrorSum = testSquaredErrorSum + ((estimatedRating - currentRating) ** 2)\n",
    "    \n",
    "    testSquaredErrorSum = testSquaredErrorSum / float(testSetCount)\n",
    "    print('Test Error (Gibbs)', testSquaredErrorSum)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllErrors_MLEVersion(in_testFileName, in_D, in_R, in_init_U, in_init_V, in_nIterations):\n",
    "    \n",
    "    U, V = CalculateMLE(gU, gV, gD, gR, in_nIterations)\n",
    "    trainingSquaredErrorSum = 0.0\n",
    "    testSquaredErrorSum = 0.0\n",
    "    \n",
    "    ##### training error\n",
    "    for eachKey in in_D.keys():\n",
    "        trainingSquaredErrorSum = trainingSquaredErrorSum + (((U[eachKey[0]].T @ V[eachKey[1]]) - in_R[eachKey]) ** 2)\n",
    "    \n",
    "    trainingSquaredErrorSum = trainingSquaredErrorSum / len(gR)\n",
    "    print('Training Error (MLE)', trainingSquaredErrorSum)\n",
    "    \n",
    "    #### test error\n",
    "    test_file = open(in_testFileName, 'r')\n",
    "    fileReader = csv.reader(test_file)\n",
    "    \n",
    "    testSquaredErrorSum = 0.0\n",
    "    testSetCount = 0\n",
    "    for row in fileReader:\n",
    "        if row[0] == 'userId':\n",
    "            continue\n",
    "        else:\n",
    "            testSetCount = testSetCount + 1\n",
    "            currentUserID = int(row[0])\n",
    "            currentMovieID = int(row[1])\n",
    "            currentRating = float(row[2])\n",
    "                \n",
    "            estimatedRating = U[currentUserID].T @ V[currentMovieID]\n",
    "            testSquaredErrorSum = testSquaredErrorSum + ((estimatedRating - currentRating) ** 2)\n",
    "    \n",
    "    testSquaredErrorSum = testSquaredErrorSum / float(testSetCount)\n",
    "    print('Test Error (MLE)', testSquaredErrorSum)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetRatingMatrixUsingMLE(in_D, in_R, in_init_U, in_initV, in_nIterations):\n",
    "    \n",
    "    U, V = CalculateMLE(gU, gV, gD, gR, in_nIterations)\n",
    "    \n",
    "    predicted_ratings = dict()\n",
    "    \n",
    "    for i in U.keys():\n",
    "        for j in V.keys():\n",
    "            predicted_ratings[(i,j)] = U[i].T @ V[j]\n",
    "    \n",
    "    return predicted_ratings\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear\n",
    "gU.clear()\n",
    "gV.clear()\n",
    "gD.clear()\n",
    "gR.clear()\n",
    "\n",
    "# Get all user id and movie id in order to avoid encontering unseen user or movie \n",
    "GenerateModelVariables (in_file_name='movie_ratings.csv', in_U=gU, in_V=gV)\n",
    "\n",
    "# Split the movie_ratings.csv file into traingSet.csv, testSet.csv\n",
    "MakeTestSet('movie_ratings.csv', 0.95, 'trainingSet.csv', 'testSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training data file to read given ratings.\n",
    "ReadTrainingCSVFile(in_file_name=\"trainingSet.csv\", out_D=gD,out_R=gR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetAllErrors_GibbsVersion(in_D=gD, in_R=gR,in_init_U=gU,in_init_V=gV,in_nSamples=2,in_testFileName='testSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetAllErrors_MLEVersion(in_D=gD, in_R=gR, in_init_U=gU, in_init_V=gV,in_testFileName='testSet.csv',in_nIterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
